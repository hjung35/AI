{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: EM Algorithm and Single-Cell RNA-seq Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Hyun Do Jung (hjung35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due December 14, 2020 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble (Don't change this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Expectation-Maximization (EM) algorithm for transcript quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The EM algorithm is a very helpful tool to compute maximum likelihood estimates of parameters in models that have some latent (hidden) variables.\n",
    "In the case of the transcript quantification problem, the model parameters we want to estimate are the transcript relative abundances $\\rho_1,...,\\rho_K$.\n",
    "The latent variables are the read-to-transcript indicator variables $Z_{ik}$, which indicate whether the $i$th read comes from the $k$th transcript (in which case $Z_{ik}=1$.\n",
    "\n",
    "In this part of the lab, you will be given the read alignment data.\n",
    "For each read and transcript pair, it tells you whether the read can be mapped (i.e., aligned) to that transcript.\n",
    "Using the EM algorithm, you will estimate the relative abundances of the trascripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading read transcript data - We have 30000 reads and 30 transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reads=30000\n",
    "n_transcripts=30\n",
    "read_mapping=[]\n",
    "with open(\"read_mapping_data.txt\",'r') as file :\n",
    "    lines_reads=file.readlines()\n",
    "for line in lines_reads :\n",
    "    read_mapping.append([int(x) for x in line.split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 8, 9], [2], [20], [5], [3], [17], [25], [7, 8, 9], [6, 8, 9], [21, 23]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_mapping[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than giving you a giant binary matrix, we encoded the read mapping data in a more concise way. read_mapping is a list of lists. The $i$th list contains the indices of the transcripts that the $i$th read maps to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading true abundances and transcript lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript_true_abundances.txt\",'r') as file :\n",
    "    lines_gt=file.readlines()\n",
    "ground_truth=[float(x) for x in lines_gt[0].split(\",\")]\n",
    "\n",
    "with open(\"transcript_lengths.txt\",'r') as file :\n",
    "    lines_gt=file.readlines()\n",
    "tr_lengths=[float(x) for x in lines_gt[0].split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0335217035814684,\n",
       " 0.001451311771258088,\n",
       " 0.06523041013235349,\n",
       " 0.005042071648942626,\n",
       " 0.013239743948342543]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4000.0, 4000.0, 3000.0, 3000.0, 1000.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_lengths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 1 : expectation_maximization (10 marks) \n",
    "\n",
    "Purpose : To implement the EM algorithm to obtain abundance estimates for each transcript.\n",
    "\n",
    "E-step :  In this step, we calculate the fraction of read that is assigned to each transcript (i.e., the estimate of $Z_{ik}$). For read $i$ and transicript $k$, this is calculated by dividing the current abundance estimate of transcript $k$ by the sum of abundance estimates of all transcripts that read $i$ maps to.\n",
    "\n",
    "M-step :  In this step, we update the abundance estimate of each transcript based on the fraction of all reads that is currently assigned to the transcript. First we compute the average fraction of all reads assigned to the transcript. Then, (if transcripts are of different lengths) we divide the result by the transcript length.\n",
    "Finally, we normalize all abundance estimates so that they add up to 1.\n",
    "\n",
    "Inputs - read_mapping (which is a list of lists where each sublist contains the transcripts to which a particular read belongs to. The length of this list is equal to the no. of reads, i.e. 30000; tr_lengths (a list containing the length of the 30 transcripts, in order); n_iterations (the number of EM iterations to be performed)\n",
    "\n",
    "Output - a list of lists where each sublist contains the abundance estimates for a transcript across all iterations. The length of each sublist should be equal to the no. of iterations plus one (for the initialization) and the total no. of sublists should be equal to the no. of transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization(read_mapping,tr_lengths,n_iterations) :\n",
    "    #start code here\n",
    "    \n",
    "    \n",
    "    \"\"\" INITIALIZATION \"\"\"\n",
    "    #initialization all rho(abundance) = 1/k\n",
    "    result = []\n",
    "    for i in range(n_transcripts):\n",
    "        g = float(\"{:.20f}\".format(1.0/n_transcripts))\n",
    "        result.append([g])\n",
    "\n",
    "    #print(result)    \n",
    "\n",
    "    # dictionary to track for each transcript's Zik values \n",
    "    dic = {0:0.0, 1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0, 6:0.0, 7:0.0, 8:0.0, 9:0.0, 10:0.0, 11:0.0, 12:0.0, 13:0.0, 14:0.0, 15:0.0, 16:0.0, 17:0.0, 18:0.0, 19:0.0, 20:0.0, 21:0.0, 22:0.0, 23:0.0, 24:0.0, 25:0.0, 26:0.0, 27:0.0, 28:0.0, 29:0.0}\n",
    "\n",
    "    # take true abundance and copy into copied_abund to not manipulate original data\n",
    "    #copied_abund = ground_truth\n",
    "    \n",
    "    for k in range(n_transcripts):\n",
    "        g = float(\"{:.20f}\".format(1.0/n_transcripts))\n",
    "        copied_abund.append(g)\n",
    "    \n",
    "    # total Z_ik_list\n",
    "    Z_ik_list = [] \n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        #print(i+1, \"iteration processing\")\n",
    "\n",
    "        \"\"\" \n",
    "        E STEP\n",
    "        we have to get Zik value by reading rho_k from copied version of true abundances \n",
    "        \"\"\"\n",
    "\n",
    "        for i_read in read_mapping:\n",
    "\n",
    "            # finding denominator value, sum of set of abundacnce of transcripts \n",
    "            tot_abund_trs = 0\n",
    "\n",
    "            for i_tr in i_read:\n",
    "                tot_abund_trs += copied_abund[i_tr]\n",
    "\n",
    "            #print(\"Sum abundance: \", tot_abund_trs)\n",
    "\n",
    "            # finding intermediate Z_ik value for each read maps\n",
    "            Z_ik_temp = []\n",
    "            for i_tr in i_read:\n",
    "                #print(\"i_th transcripts: \", i_tr, \"in\", \"read list: \",i_read, end='\\n')\n",
    "                #print(i_tr, ground_truth[i_tr-1], tot_abund_trs)\n",
    "                Zik = copied_abund[i_tr] / tot_abund_trs\n",
    "                #print(\"calc Zik: \", Zik)\n",
    "                Z_ik_temp.append(Zik)\n",
    "\n",
    "\n",
    "                \"\"\"THIS IS FOR M STEP where we want summation of all Zik for each k transcript\"\"\"\n",
    "                # summing up each transcript k's Z_ik value using dict \n",
    "                dic[i_tr] += Zik\n",
    "\n",
    "            #whole Z_ik_list(list of lists)     \n",
    "            Z_ik_list.append(Z_ik_temp)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "        M STEP\n",
    "        summation of Zik for each read maps to the k th transcript\n",
    "        starting from 0 to 29, iterate through the dict where we have summation of each Zik per k_th transcript\n",
    "        we get each of these values and divided by n_reads and tr_length \n",
    "        \"\"\"\n",
    "\n",
    "        Sum = 0.00\n",
    "\n",
    "        # iteration from 0 to 29\n",
    "        for i_tr in dic:\n",
    "            #current Z_ik value starting from 0 to 29\n",
    "            cur_Z_ik = dic.get(i_tr)\n",
    "\n",
    "            #new rho_k calculation\n",
    "            rho_k = float(\"{:.20f}\".format(cur_Z_ik / (n_reads * tr_lengths[i_tr])))\n",
    "            #print(rho_k)\n",
    "\n",
    "            Sum += rho_k\n",
    "\n",
    "\n",
    "        #normalization\n",
    "        for i_tr in dic:\n",
    "            norm_const = 1.0/Sum\n",
    "            norm_const = float(\"{:.20f}\".format(norm_const))\n",
    "            cur_Z_ik = dic.get(i_tr)\n",
    "            rho_k = float(\"{:.20f}\".format(cur_Z_ik / (n_reads * tr_lengths[i_tr])))\n",
    "            #print(rho_k)\n",
    "            norm_k = norm_const * rho_k\n",
    "            #print(norm_k)\n",
    "            copied_abund[i_tr] = norm_k\n",
    "            #print(copied_abund)\n",
    "            result[i_tr].append(norm_k)\n",
    "\n",
    "\n",
    "\n",
    "        #norm_k = scalar.fit_transform(dic)\n",
    "\n",
    "    Sum = 0 \n",
    "    for i in range(30):\n",
    "        temp = result[i][20]\n",
    "        #print(temp)\n",
    "        Sum+=temp\n",
    "    #print(Sum)        \n",
    "\n",
    "    #print(result[0][-5:])\n",
    "    #print(result[1][-5:])\n",
    "    #print(result[2][-5:])\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333], [0.03333333333333333]]\n",
      "1 iteration processing\n",
      "2 iteration processing\n",
      "3 iteration processing\n",
      "4 iteration processing\n",
      "5 iteration processing\n",
      "6 iteration processing\n",
      "7 iteration processing\n",
      "8 iteration processing\n",
      "9 iteration processing\n",
      "10 iteration processing\n",
      "11 iteration processing\n",
      "12 iteration processing\n",
      "13 iteration processing\n",
      "14 iteration processing\n",
      "15 iteration processing\n",
      "16 iteration processing\n",
      "17 iteration processing\n",
      "18 iteration processing\n",
      "19 iteration processing\n",
      "20 iteration processing\n",
      "0.9999999999999999\n",
      "[0.03394615522444801, 0.03394615411014984, 0.03394615307297099, 0.03394615210379448, 0.033946151194982]\n",
      "[0.0018317517304790214, 0.0018317528447739004, 0.0018317538819547783, 0.001831754851135847, 0.0018317557599526525]\n",
      "[0.06608997818389019, 0.0660899781935431, 0.066089978202478, 0.06608997821078116, 0.06608997821853264]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "from fractions import Fraction\n",
    "\n",
    "\n",
    "\"\"\" INITIALIZATION \"\"\"\n",
    "#initialization all rho(abundance) = 1/k\n",
    "result = []\n",
    "for i in range(30):\n",
    "    g = float(\"{:.20f}\".format(1.0/n_transcripts))\n",
    "    result.append([g])\n",
    "\n",
    "print(result)    \n",
    "    \n",
    "# dictionary to track for each transcript's Zik values \n",
    "dic = {0:0.0, 1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0, 6:0.0, 7:0.0, 8:0.0, 9:0.0, 10:0.0, 11:0.0, 12:0.0, 13:0.0, 14:0.0, 15:0.0, 16:0.0, 17:0.0, 18:0.0, 19:0.0, 20:0.0, 21:0.0, 22:0.0, 23:0.0, 24:0.0, 25:0.0, 26:0.0, 27:0.0, 28:0.0, 29:0.0}\n",
    "\n",
    "# take true abundance and copy into copied_abund to not manipulate original data\n",
    "#copied_abund = ground_truth\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    copied_abund.append(1.0/n_transcripts)\n",
    "\n",
    "# total Z_ik_list\n",
    "Z_ik_list = [] \n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    print(i+1, \"iteration processing\")\n",
    "    \n",
    "    \"\"\" \n",
    "    E STEP\n",
    "    we have to get Zik value by reading rho_k from copied version of true abundances \n",
    "    \"\"\"\n",
    "    \n",
    "    for i_read in read_mapping:\n",
    "\n",
    "        # finding denominator value, sum of set of abundacnce of transcripts \n",
    "        tot_abund_trs = 0\n",
    "        \n",
    "        for i_tr in i_read:\n",
    "            tot_abund_trs += copied_abund[i_tr]\n",
    "\n",
    "        #print(\"Sum abundance: \", tot_abund_trs)\n",
    "\n",
    "        # finding intermediate Z_ik value for each read maps\n",
    "        Z_ik_temp = []\n",
    "        for i_tr in i_read:\n",
    "            #print(\"i_th transcripts: \", i_tr, \"in\", \"read list: \",i_read, end='\\n')\n",
    "            #print(i_tr, ground_truth[i_tr-1], tot_abund_trs)\n",
    "            Zik = copied_abund[i_tr] / tot_abund_trs\n",
    "            #print(\"calc Zik: \", Zik)\n",
    "            Z_ik_temp.append(Zik)\n",
    "\n",
    "\n",
    "            \"\"\"THIS IS FOR M STEP where we want summation of all Zik for each k transcript\"\"\"\n",
    "            # summing up each transcript k's Z_ik value using dict \n",
    "            dic[i_tr] += Zik\n",
    "\n",
    "        #whole Z_ik_list(list of lists)     \n",
    "        Z_ik_list.append(Z_ik_temp)\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    M STEP\n",
    "    summation of Zik for each read maps to the k th transcript\n",
    "    starting from 0 to 29, iterate through the dict where we have summation of each Zik per k_th transcript\n",
    "    we get each of these values and divided by n_reads and tr_length \n",
    "    \"\"\"\n",
    "\n",
    "    Sum = 0.00\n",
    "    \n",
    "    # iteration from 0 to 29\n",
    "    for i_tr in dic:\n",
    "        #current Z_ik value starting from 0 to 29\n",
    "        cur_Z_ik = dic.get(i_tr)\n",
    "\n",
    "        #new rho_k calculation\n",
    "        rho_k = cur_Z_ik / (n_reads * tr_lengths[i_tr])\n",
    "        #print(rho_k)\n",
    "\n",
    "        Sum += rho_k\n",
    "        \n",
    "    \n",
    "    #normalization\n",
    "    for i_tr in dic:\n",
    "        norm_const = 1.0/Sum\n",
    "        norm_const = float(\"{:.20f}\".format(norm_const))\n",
    "        cur_Z_ik = dic.get(i_tr)\n",
    "        rho_k = float(\"{:.20f}\".format(cur_Z_ik / (n_reads * tr_lengths[i_tr])))\n",
    "        #print(rho_k)\n",
    "        norm_k = norm_const * rho_k\n",
    "        #print(norm_k)\n",
    "        copied_abund[i_tr] = norm_k\n",
    "        #print(copied_abund)\n",
    "        result[i_tr].append(norm_k)\n",
    "\n",
    "\n",
    "     \n",
    "    #norm_k = scalar.fit_transform(dic)\n",
    "\n",
    "Sum = 0 \n",
    "for i in range(30):\n",
    "    temp = result[i][20]\n",
    "    #print(temp)\n",
    "    Sum+=temp\n",
    "print(Sum)        \n",
    "        \n",
    "print(result[0][-5:])\n",
    "print(result[1][-5:])\n",
    "print(result[2][-5:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "21\n",
      "[0.033946089903192984, 0.03394608973288917, 0.03394608957437258, 0.03394608942624908, 0.033946089287350885]\n",
      "[0.0018318170517546276, 0.0018318172220567201, 0.0018318173805729346, 0.0018318175286966471, 0.0018318176675945314]\n",
      "[0.06608997862426405, 0.06608997862488816, 0.06608997862545997, 0.0660899786259843, 0.06608997862647896]\n"
     ]
    }
   ],
   "source": [
    "history=expectation_maximization(read_mapping,tr_lengths,20)\n",
    "print(len(history))\n",
    "print(len(history[0]))\n",
    "print(history[0][-5:])\n",
    "print(history[1][-5:])\n",
    "print(history[2][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output - \n",
    "\n",
    "30\n",
    "\n",
    "21\n",
    "\n",
    "[0.033769639494636614, 0.03381298624783303, 0.03384568373972948, 0.0338703482393148, 0.03388895326082054]\n",
    "\n",
    "[0.0020082674603036053, 0.0019649207071071456, 0.0019322232152109925, 0.0019075587156241912, 0.0018889536941198502]\n",
    "\n",
    "[0.0660581789629968, 0.06606927656035864, 0.06607650126895578, 0.06608120466668756, 0.0660842666518177]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 2 : visualize_em (10 marks)\n",
    "\n",
    "Purpose : To plot the trajectories of the abundance estimate of each transcript with the number of iterations. To see whether the abundances are converging to the ground truth, you should plot the difference between the abundance estimates for a given transcript (say, ``history[k]``) and the ground truth ``ground_truth[k]``\n",
    "\n",
    "Input - a list of lists where each sublist contains the abundance estimates for a transcript across all iterations. The length of each sublist should be equal to the no. of iterations and the total no. of sublists should be equal to the no. of transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_em(history,n_iterations) :\n",
    "    #start code here\n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(len(history)):\n",
    "        #print(\"i:\", i)\n",
    "        temp=[]\n",
    "        for j in range(n_iterations):\n",
    "            #print(j)\n",
    "\n",
    "            x = history[i][j] - ground_truth[i]\n",
    "            #print(x)\n",
    "            temp.append(x)\n",
    "        plt.plot(temp, linestyle='-.')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_em(history,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output -\n",
    "\n",
    "![expected_plot.png](expected_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Exploring Single-Cell RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a study published in 2015, Zeisel et al. used single-cell RNA-seq data to explore the cell diversity in the mouse brain. \n",
    "We will explore the data used for their study.\n",
    "You can read more about it [here](https://science.sciencemag.org/content/347/6226/1138)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading single-cell RNA-seq data\n",
    "lines_genes=[]\n",
    "with open(\"Zeisel_expr.txt\",'r') as file :\n",
    "    lines_genes=file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 0 3 0 0 3 0 0 0 2 0 0 0 0 0 4 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 2 0 0 1 2 6 7 2 0 0 0 2 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 3 13 2 1 2 1 0 3 2 0 0 2 1 0 0 2 3 6 0 1 5 0 0 1 1 4 0 4 0 1 0 0 1 2 5 0 0 5 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 3 1 0 0 2 0 0'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_genes[0][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line in the file Zeisel_expr.txt corresponds to one gene.\n",
    "The columns correspond to different cells (notice that this is the opposite of how we looked at this matrix in class).\n",
    "The entries of this matrix correspond to the number of reads mapping to a given gene in the corresponding cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading true labels for each cell\n",
    "with open(\"Zeisel_labels.txt\",'r') as file :\n",
    "    true_labels = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study also provides us with true labels for each of the cells.\n",
    "For each of the cells, the vector true_labels contains the name of the cell type.\n",
    "There are nine different cell types in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Astrocytes',\n",
       " 'CA1 Pyrimidal',\n",
       " 'Endothelial',\n",
       " 'Ependymal',\n",
       " 'Interneurons',\n",
       " 'Microglia',\n",
       " 'Mural',\n",
       " 'Oligodentrocytes',\n",
       " 'S1 Pyrimidal'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 3 : prepare_data (10 marks) :\n",
    "\n",
    "Purpose - To create a dataframe where each row corresponds to a specific cell and each column corresponds to the expressions levels of a particular gene across all cells. \n",
    "You should name the columns as \"Gene_1\", \"Gene_2\", and so on.\n",
    "\n",
    "We will iterate through all the lines in lines_genes list created above, add 1 to each value and take log.\n",
    "\n",
    "Each line will correspond to 1 column in the dataframe\n",
    "\n",
    "Output - gene expression dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data() :\n",
    "    #start code here\n",
    "    df=pd.DataFrame()\n",
    "\n",
    "\n",
    "    for i in range(len(lines_genes)):\n",
    "        col_name = 'Gene_' + str(i)\n",
    "\n",
    "        line = lines_genes[i].strip().split()\n",
    "\n",
    "        # loop to find each digit entry\n",
    "        col_temp = []\n",
    "        for i in range(len(line)):    \n",
    "            entry = np.int(line[i])\n",
    "            entry += 1\n",
    "            entry = np.log(entry)\n",
    "            col_temp.append(entry)\n",
    "        #print(col_temp)\n",
    "        df[col_name] = col_temp\n",
    "\n",
    "    return df\n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005, 19972)\n",
      "   Gene_0    Gene_1    Gene_2  Gene_3    Gene_4\n",
      "0     0.0  1.386294  1.386294     0.0  0.693147\n",
      "1     0.0  0.693147  0.693147     0.0  0.693147\n",
      "2     0.0  0.000000  1.945910     0.0  0.693147\n"
     ]
    }
   ],
   "source": [
    "data_df=prepare_data()\n",
    "print(data_df.shape)\n",
    "print(data_df.iloc[0:3,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output :\n",
    "\n",
    "``(3005, 19972)``\n",
    "\n",
    "``   Gene_0    Gene_1    Gene_2  Gene_3    Gene_4``\n",
    "   \n",
    "``0     0.0  1.386294  1.386294     0.0  0.693147``\n",
    "\n",
    "``1     0.0  0.693147  0.693147     0.0  0.693147``\n",
    "\n",
    "``2     0.0  0.000000  1.945910     0.0  0.693147``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 4 : identify_less_expressive_genes (10 marks)\n",
    "\n",
    "Purpose : To identify genes (columns) that are expressed in less than 25 cells. We will create a list of all gene columns that have values greater than 0 for less than 25 cells.\n",
    "\n",
    "Input - gene expression dataframe\n",
    "\n",
    "Output - list of column names which are expressed in less than 25 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_less_expressive_genes(df) :\n",
    "    #start code here\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        temp = []\n",
    "        cnt = 0 \n",
    "        limit = 25\n",
    "        \n",
    "        for j in range(df.shape[0]):\n",
    "\n",
    "            col_name = df.columns[i]\n",
    "\n",
    "            if df[col_name][j] > 0:\n",
    "                cnt += 1\n",
    "                \n",
    "                if(cnt == limit):\n",
    "                    break\n",
    "                    \n",
    "        if cnt < limit:\n",
    "            result.append(col_name)\n",
    "                \n",
    "    return result\n",
    "    \n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120\n",
      "['Gene_28', 'Gene_126', 'Gene_145', 'Gene_146', 'Gene_151', 'Gene_152', 'Gene_167', 'Gene_168', 'Gene_170', 'Gene_173']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = identify_less_expressive_genes(data_df)\n",
    "print(len(drop_columns))\n",
    "print(drop_columns[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output : \n",
    "\n",
    "``5120`` \n",
    "\n",
    "``['Gene_28', 'Gene_126', 'Gene_145', 'Gene_146', 'Gene_151', 'Gene_152', 'Gene_167', 'Gene_168', 'Gene_170', 'Gene_173']``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering less expressive genes\n",
    "\n",
    "We will now create a new dataframe in which genes which are expressed in less than 25 cells will not be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = data_df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_0</th>\n",
       "      <th>Gene_1</th>\n",
       "      <th>Gene_2</th>\n",
       "      <th>Gene_3</th>\n",
       "      <th>Gene_4</th>\n",
       "      <th>Gene_5</th>\n",
       "      <th>Gene_6</th>\n",
       "      <th>Gene_7</th>\n",
       "      <th>Gene_8</th>\n",
       "      <th>Gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Gene_19947</th>\n",
       "      <th>Gene_19948</th>\n",
       "      <th>Gene_19951</th>\n",
       "      <th>Gene_19952</th>\n",
       "      <th>Gene_19953</th>\n",
       "      <th>Gene_19955</th>\n",
       "      <th>Gene_19956</th>\n",
       "      <th>Gene_19957</th>\n",
       "      <th>Gene_19959</th>\n",
       "      <th>Gene_19960</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gene_0    Gene_1    Gene_2  Gene_3    Gene_4  Gene_5    Gene_6    Gene_7  \\\n",
       "0  0.000000  1.386294  1.386294     0.0  0.693147     0.0  0.000000  2.484907   \n",
       "1  0.000000  0.693147  0.693147     0.0  0.693147     0.0  0.000000  0.000000   \n",
       "2  0.000000  0.000000  1.945910     0.0  0.693147     0.0  1.098612  3.258097   \n",
       "3  1.386294  1.098612  1.609438     0.0  0.000000     0.0  1.386294  0.693147   \n",
       "4  0.000000  1.098612  0.693147     0.0  0.000000     0.0  0.000000  2.397895   \n",
       "\n",
       "     Gene_8  Gene_9  ...  Gene_19947  Gene_19948  Gene_19951  Gene_19952  \\\n",
       "0  0.693147     0.0  ...    2.079442         0.0    0.000000         0.0   \n",
       "1  0.000000     0.0  ...    0.693147         0.0    0.000000         0.0   \n",
       "2  0.693147     0.0  ...    0.693147         0.0    1.098612         0.0   \n",
       "3  0.000000     0.0  ...    1.386294         0.0    0.693147         0.0   \n",
       "4  0.000000     0.0  ...    0.000000         0.0    1.609438         0.0   \n",
       "\n",
       "   Gene_19953  Gene_19955  Gene_19956  Gene_19957  Gene_19959  Gene_19960  \n",
       "0         0.0    1.791759         0.0         0.0         0.0    0.000000  \n",
       "1         0.0    0.000000         0.0         0.0         0.0    0.000000  \n",
       "2         0.0    1.386294         0.0         0.0         0.0    2.079442  \n",
       "3         0.0    0.000000         0.0         0.0         0.0    0.000000  \n",
       "4         0.0    1.386294         0.0         0.0         0.0    0.000000  \n",
       "\n",
       "[5 rows x 14852 columns]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 5 :  perform_pca (10 marks)\n",
    "\n",
    "Pupose - Perform Principal Component Analysis on the new dataframe and take the top 50 principal components\n",
    "\n",
    "Input - df_new\n",
    "\n",
    "Output - numpy array containing the top 50 principal components of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(df) :\n",
    "    #start code here\n",
    "    \n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-f9b8a3c4beb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "fd = df_new.iloc[:,:3000]\n",
    "#print(fd)\n",
    "data = fd[fd.columns[:]]\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca_fit = pca.fit(data)\n",
    "\n",
    "print(pca_fit.shape)\n",
    "print(type(pca_fit))\n",
    "print(pca_fit[0:3,:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005, 14852)\n"
     ]
    }
   ],
   "source": [
    "fd = df_new.iloc[:,:]\n",
    "#print(fd.columns[0].shape)\\\n",
    "#fd = df_new\n",
    "print(fd.shape)\n",
    "result =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(fd.shape[1]):\n",
    "\n",
    "\n",
    "    col_name = fd.columns[i]\n",
    "    x = fd.drop([col_name], axis=1).values\n",
    "    y = fd[col_name].values\n",
    "    #print(x.shape)\n",
    "    pca = PCA(n_components=50)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    \n",
    "        #print(x)\n",
    "        #pca=PCA(n_components = 1)\n",
    "        #pC=pca.fit_transform(fd)\n",
    "        #pca.fit(fd[col_name])\n",
    "        #print(pC)\n",
    "        #result.append([pC])\n",
    "print(principalComponents.shape)\n",
    "print(type(principalComponents))\n",
    "print(principalComponents[0:3,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data=perform_pca(df_new)\n",
    "print(pca_data.shape)\n",
    "print(type(pca_data))\n",
    "print(pca_data[0:3,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output : \n",
    "\n",
    "``(3005, 50)``\n",
    "\n",
    "``<class 'numpy.ndarray'>``\n",
    "\n",
    "``[[26.9714913  -2.72440136  0.62164446 25.90148292 -6.24736945]``\n",
    "\n",
    "`` [26.49135772 -1.58774171 -4.79314022 24.01094206 -7.25618285]``\n",
    " \n",
    "`` [47.82665332  5.06798931  2.15178143 30.24366515 -3.38878807]]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 6 :  perform_tsne (10 marks)\n",
    "\n",
    "Pupose - Perform t-SNE on the pca_data and obtain 2 t-SNE components\n",
    "\n",
    "We will use TSNE class of the sklearn.manifold package. Use random_state=1000 and perplexity=50\n",
    "\n",
    "Documenation can be found here - https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "\n",
    "Input - pca_data\n",
    "\n",
    "Output - numpy array containing the top 2 tsne components of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tsne(pca_data) :\n",
    "    #start code here\n",
    "    \n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data50 = perform_tsne(pca_data)\n",
    "print(tsne_data50.shape)\n",
    "print(tsne_data50[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output :\n",
    "\n",
    "(These numbers can deviate a bit depending on your sklearn)\n",
    "\n",
    "``(3005, 2)``\n",
    "\n",
    "``[[ 15.069608 -47.535984]``\n",
    "\n",
    "`` [ 15.251476 -47.172073]``\n",
    " \n",
    "`` [ 13.3932   -49.909657]]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot(tsne_data50[:,0], tsne_data50[:,1], hue=true_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the different cell types form clusters (which can be easily visualized on the t-SNE space).\n",
    "Zeisel et al. performed clustering on this data in order to identify and label the different cell types.\n",
    "\n",
    "You can try using clustering methods discussed in the first module of the course (such as k-means) to cluster the single-cell RNA-seq data of Zeisel at al. and see if your results agree with theirs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
